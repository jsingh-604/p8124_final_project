{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44323f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Assorting Downloaded Data into Trainable Format ######3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c631c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "path = '/Volumes/drive/'\n",
    "lis = ['001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012']\n",
    "for l in lis:\n",
    "    fn = 'images_' + l + '.tar.gz'\n",
    "    # open file\n",
    "    file = tarfile.open('/Volumes/drive/im/CXR8/images/' + fn)\n",
    "    file.extractall('/Volumes/drive/image_data2/')\n",
    "    file.close()\n",
    "    print(fn)\n",
    "\n",
    "labels_df = pd.read_csv(\"labels.csv\")\n",
    "labels_df['Index'] = labels_df['Image Index']\n",
    "labels_df = labels_df.query('Index.isin(@dir_list)')\n",
    "labels = labels_df.sort_values('Finding Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', \n",
    "'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening','Hernia', 'No Finding']\n",
    "\n",
    "train_images = '/train'\n",
    "train_cat = '/train_'\n",
    "#creating subfolders\n",
    "for i in class_names:\n",
    "    os.makedirs(os.path.join('train_', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving the image files to their respective categories\n",
    "import shutil\n",
    "for c in class_names: # Category Name\n",
    "    for i in list(labels[labels['Finding Labels']==c]['Image Index']): # Image Id\n",
    "        try:\n",
    "            get_image = os.path.join('image_data/images/', i)\n",
    "            move_image_to_cat = shutil.move(get_image, 'train_/'+c)# Path to Images\n",
    "            \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### CNN ####################################\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df44edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/Jag/Documents/train_/',\n",
    "  image_size= (128,128),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  color_mode='rgb',\n",
    "  batch_size= 32,\n",
    "  seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d81598",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## using validation data for test purposes instead of validation #######\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/Jag/Documents/train_/',\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  color_mode = \"rgb\",\n",
    "  batch_size = 32,\n",
    "  seed=123,\n",
    "  image_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bae7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class_names = train_ds.class_names\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    v = images[i].numpy().astype(\"uint8\")\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache()\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93623dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(128, 128, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffab100",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9935086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9488bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e6e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faafcdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f223cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate thru all the layers of the model\n",
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        weights, bias= layer.get_weights()\n",
    "        \n",
    "        #normalize filter values between  0 and 1 for visualization\n",
    "        f_min, f_max = weights.min(), weights.max()\n",
    "        filters = (weights - f_min) / (f_max - f_min)  \n",
    "        print(filters.shape[3])\n",
    "        filter_cnt=1\n",
    "        \n",
    "        #plotting all the filters\n",
    "        for i in range(filters.shape[3]):\n",
    "            #get the filters\n",
    "            filt=filters[:,:,:, i]\n",
    "            #plotting each of the channel, color image RGB channels\n",
    "            for j in range(filters.shape[0]):\n",
    "                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(filt[:,:, j])\n",
    "                filter_cnt+=1\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.shape(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca095105",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = v\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "# Let's run input image through our vislauization network\n",
    "# to obtain all intermediate representations for the image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "# Retrieve are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  print(feature_map.shape)\n",
    "  if len(feature_map.shape) == 4:\n",
    "    \n",
    "    # Plot Feature maps for the conv / maxpool layers, not the fully-connected layers\n",
    "   \n",
    "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
    "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
    "    \n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    \n",
    "    # Postprocess the feature to be visually palatable\n",
    "    for i in range(n_features):\n",
    "      x  = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std ()\n",
    "      x *=  64\n",
    "      x += 128\n",
    "      x  = np.clip(x, 0, 255).astype('uint8')\n",
    "      # Tile each filter into a horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "# Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure( figsize=(scale * n_features, scale) )\n",
    "    plt.title ( layer_name )\n",
    "    plt.grid  ( False )\n",
    "    plt.imshow( display_grid, aspect='auto', cmap='viridis' )\n",
    "    plt.savefig(\"fig1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f69dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.models.Model(inputs=model.inputs , outputs=model.layers[1].output)\n",
    "#calculating features_map\n",
    "x = v\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "features = mod.predict(x)\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "for i in range(1,features.shape[3]+1):\n",
    "\n",
    "    plt.subplot(8,8,i)\n",
    "    plt.imshow(features[0,:,:,i-1] , cmap='viridis')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe23c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Building VAE ############################\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset= tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/Jag/Documents/train_/',\n",
    "  image_size= (128,128),\n",
    "  color_mode= \"rgb\",\n",
    "  validation_split=0.2,\n",
    "  subset = 'training',\n",
    "  batch_size= 32,\n",
    "  seed=123)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = dataset.map(lambda x, y: normalization_layer(x))\n",
    "\n",
    "train_ds = normalized_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ce7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 6272\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(128, 128, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbf86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(32 * 32 * 8, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((32, 32, 8))(x)\n",
    "x = layers.Conv2DTranspose(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103fb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(train_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save('encoder_6272')\n",
    "decoder.save('decoder_6272')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/Jag/Documents/train_/',\n",
    "  image_size= (128,128),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  color_mode='rgb',\n",
    "  batch_size= 32,\n",
    "  seed=123)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "class_names = train_ds.class_names\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(3):\n",
    "  for i in range(6):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    v = np.expand_dims(images[i].numpy(), axis = 0)\n",
    "    z_mean, z_log_var, z = vae.encoder.predict(v)\n",
    "    reconstruction = decoder(z)\n",
    "    v = reconstruction.numpy()\n",
    "    ve = np.squeeze(v)\n",
    "    plt.imshow(ve)\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_label_clusters(vae, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "    ax = sns.scatterplot(x = z_mean[:, 0]/255,y = z_mean[:, 1]/255, hue=labels)\n",
    "    ax.set(xlabel='Dimension 1', ylabel='Dimension 2')\n",
    "    ax.set_title(\"Projection of 2D Latent Space (X-Ray Scans)\")\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "plot_label_clusters(vae, train_ds.take(25), class_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### ENCODER + MLP ##################\n",
    "\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/Jag/Documents/train_/',\n",
    "  image_size= (128,128),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  color_mode='rgb',\n",
    "  batch_size= 32,\n",
    "  seed=123)\n",
    "\n",
    "\n",
    "encoder = tf.keras.models.load_model('encoder_6272', compile = 'False')\n",
    "decoder = tf.keras.models.load_model('decoder_6272', compile = 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_list = []\n",
    "test_label_list = []\n",
    "i = 0\n",
    "for images,labels in train_ds:\n",
    "    for i in range(32):\n",
    "        try:\n",
    "            train_label_list.append(labels[i].numpy())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "for images,labels in test_ds:\n",
    "    for i in range(32):\n",
    "        try:\n",
    "            test_label_list.append(labels[i].numpy())\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2209f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var, z =  encoder.predict(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_mean, v_log_var, v =  encoder.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc52462",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_ds.class_names)\n",
    "enc_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(32),\n",
    "  tf.keras.layers.Dropout(0.2)\n",
    "])\n",
    "enc_model.add(tf.keras.layers.Dense(15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9737596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(z)\n",
    "y = np.array(train_label_list)\n",
    "X_test = np.array(v)\n",
    "y_test = np.array(test_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a46c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_history = enc_model.fit(X,y, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04adcf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "acc = enc_history.history['accuracy']\n",
    "loss = enc_history.history['loss']\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model.save(\"enc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d251ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## MODEL COMPARISON #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluaton\n",
    "print(\"Evaluateion on test data for CNN model \")\n",
    "results = model.evaluate(test_ds, batch_size=32)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "print(\"Evaluate on test data for encoder + MLP\")\n",
    "results = enc_model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02845d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ ALTERNATE METHOD: RBM ################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.neural_network import BernoulliRBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c84cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/Jag/Documents/train_/',\n",
    "  image_size= (128,128),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  color_mode='grayscale',\n",
    "  batch_size= 32,\n",
    "  seed=123)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/Jag/Documents/train_/',\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  color_mode = \"grayscale\",\n",
    "  batch_size = 32,\n",
    "  seed=123,\n",
    "  image_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d332ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_list = []\n",
    "test_image_list = []\n",
    "train_label_list = []\n",
    "test_label_list = []\n",
    "i = 0\n",
    "for images,labels in train_ds.take(100):\n",
    "    for i in range(32):\n",
    "        try:\n",
    "            train_image_list.append(images[i].numpy())\n",
    "            train_label_list.append(labels[i].numpy())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "for images,labels in test_ds.take(100):\n",
    "    for i in range(32):\n",
    "        try:\n",
    "            test_image_list.append(images[i].numpy())\n",
    "            test_label_list.append(labels[i].numpy())\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5660be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_image_list)\n",
    "y = np.array(train_label_list)\n",
    "X_test = np.array(test_image_list)\n",
    "y_test = np.array(test_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c46f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6416fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_data.npy', X)\n",
    "np.save('train_labels.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encoded_data.npy', 'rb') as f:\n",
    "        X = np.load(f)\n",
    "\n",
    "with open('train_labels.npy', 'rb') as f:\n",
    "        y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd76137",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.reshape(-1, 128*128*1)/255\n",
    "X_test = X_test.reshape(-1, 128*128*1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41645c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.where(X_train > 0.2, 1, 0)\n",
    "X_test = np.where(X_test > 0.2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "for i in range(5):\n",
    "  plt.subplot(2,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(X_train[i].reshape(128,128,1), cmap='Greys')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbeb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = BernoulliRBM(n_components=100, learning_rate=0.01, random_state=42, verbose=True)\n",
    "rbm.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2154cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "neu = MLPClassifier(hidden_layer_sizes=(128,32,15),activation=\"relu\")\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "rbm_features_classifier = Pipeline(steps=[(\"rbm\", rbm), (\"new\", neu)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 10\n",
    "\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "# Training RBM-Logistic Pipeline\n",
    "rbm_features_classifier.fit(X_train, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5693fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "Y_train= rbm_features_classifier.predict(X_train)\n",
    "print(\n",
    "    \"Logistic regression using RBM features:\\n%s\\n\"\n",
    "    % metrics.classification_report(y, Y_train)#(metrics.classification_report(y_test, Y_pred))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = rbm_features_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, comp in enumerate(rbm.components_):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(comp.reshape((128, 128)), cmap='Accent',\n",
    "               interpolation='nearest', vmin=-2.5, vmax=2.5)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b209b0a8e5fedb54ae8c66a0b110de42675b7c0f0b60a0826117595acfa9590"
  },
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
